- ecosystem 1 - kafka client
    - kafka와 데이터를 주고 받기 위해 사용하는 java lib
    - Producer, Consumer, Admin, Stream 등 kafka 관련 api 제공
    - 다양한 3rd party lib존재
    - 명령어
        - kafka 서버 기동
            - /Users/jicheol/study-inflearn/microservice/kafka_2.13-3.2.0
            - zookeeper 및 kafka 서버 구동
            - ./bin/zookeeper-server-start.sh ./config/zookeeper.properties
            - ./bin/kafka-server-start.sh ./config/server.properties
        - topic 생성
            - ./bin/kafka-topics.sh --bootstrap-server localhost:9092 --create --topic 토픽이름 --partitions 1
        - topic 목록 확인
            - ./bin/kafka-topics.sh --bootstrap-server [localhost:9092](http://localhost:9092) --list
        - topic 정보 확인
            - ./bin/kafka-topics.sh --bootstrap-server localhost:9092 --describe --topic quickstart-events
        - producer
            - ./bin/kafka-console-producer.sh --broker-list localhost:9092 --topic quickstart-events
        - consumer
            - ./bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic quickstart-events --from-beginning

---

- ecosystem 2 - kafka connect
    - kafka connect를 통해 data를 import/export 가능
    - 코드 없이 configuration으로 데이터를 이동
    - standalone mode, Distribution mode 지원
        - RESTful API 통해 지원
        - stream 또는 Batch 형태로 데이터 전송 가능
        - 커스텀 Connector를 통한 다양한 Plugin 제공 (File, S3, Hive, Mysql, etc …)
    - source → kafka connect source → kafka cluster → kafka connect sink → target
    - 세팅
        
        ### **Kafka Connect 설치**
        
        curl -O http://packages.confluent.io/archive/5.5/confluent-community-5.5.2-2.12.tar.gz
        
        curl -O http://packages.confluent.io/archive/6.1/confluent-community-6.1.0.tar.gz
        
        tar xvf confluent-community-6.1.0.tar.gz
        
        cd  $KAFKA_CONNECT_HOME
        
        ### **Kafka Connect 실행**
        
        ./bin/connect-distributed ./etc/kafka/connect-distributed.properties
        
        ### **JDBC Connector 설치**
        
        - https://docs.confluent.io/5.5.1/connect/kafka-connect-jdbc/index.html
        - confluentinc-kafka-connect-jdbc-10.0.1.zip
        
        ### **etc/kafka/connect-distributed.properties 파일 마지막에 아래 plugin 정보 추가**
        
        - plugin.path=[confluentinc-kafka-connect-jdbc-10.0.1 폴더]
        
        ### **JdbcSourceConnector에서 MariaDB 사용하기 위해 mariadb 드라이버 복사**
        
        ./share/java/kafka/ 폴더에 mariadb-java-client-2.7.2.jar  파일 복사
        

---

- mariadb
    - 🤔 mariadb vs mysql ????

---

- 말씀하신 방법으로 Producer와 Consumer를 각각 구현하시고, DB 연동 작업을 통해 데이터의 이전을 처리하셔도 됩니다. Kafka Connect의 목적은 프로그래밍을 하지 않고도, 하나의 Resource에서 다른 Resource로 데이터를 이전하는 목적이 있습니다. Kafka 애플리케이션과 Kafka Connect의 장단점과 사용 목적에 따라 구분하여 사용하시면 좋을 것 같습니다. Kafka Connect의 Connector를 재정의해서 사용하시면, 코드의 양을 줄이면서 프로그래밍 언어에 종속적이지 않은 서비스를 구축하실 수 있습니다. [http://kafka.apache.org/documentation/#connect](http://kafka.apache.org/documentation/#connect) 
Kafka Connect이외에도 Kafka Stream(http://kafka.apache.org/documentation/streams/)나 ksqlDB(https://www.confluent.io/product/ksql/)를 통해 대용량의 데이터를 빠른 속도로 데이터베이스로 스트링 해주는 서비스들도 있으니 관심있으시면 같은 살펴 보시는것도 추천 드립니다.
감사합니다.

---

- CatalogService
    - spring-kafka dependency 추가
    - Consumer configure 빈 추가
        
        ```java
        @EnableKafka
        @Configuration
        public class KafkaConsumerConfig {
        		@Bean
        		public ConsumerFactory<String, String> consumerFactory() {}
        
        		@Bean
        		public ConcurrentKafkaListenerContainerFactory<String, String> kafkaListenerContainerFactory() {}
        }
        ```
        
    - Consumer service 추가
        
        ```java
        @KafkaListener(topics = "example-catalog-topic")
        public void updateQty(String kafkaMessage) {}
        ```
        
- OrderService
    - spring-kafka dependency 추가
    - Producer configure 빈 추가
        
        ```java
        @EnableKafka
        @Configuration
        public class KafkaProducerConfig {
            @Bean
            public ProducerFactory<String, String> producerFactory() {}
        		@Bean
            public KafkaTemplate<String, String> kafkaTemplate() {}
        ```
        
    - KafkaTemplate를 이용해 send
        
        ```java
        kafkaTemplate.send(topic, jsonInString);
        ```
        
- 복수의 서비스 → kafka → 하나의 디비
- 복수의 서비스 → 여러개의 디비 (kafka 통한 동기화)

---

- 🤔 CQRS 패턴
